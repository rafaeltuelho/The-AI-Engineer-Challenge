# Import required FastAPI components for building the API
from fastapi import FastAPI, HTTPException, Request, UploadFile, File, Form, Header
from fastapi.responses import StreamingResponse
from fastapi.middleware.cors import CORSMiddleware
# Import Pydantic for data validation and settings management
from pydantic import BaseModel, field_validator
# Import OpenAI client for interacting with OpenAI's API
from openai import OpenAI
# Import slowapi for rate limiting
from slowapi import Limiter, _rate_limit_exceeded_handler
from slowapi.util import get_remote_address
from slowapi.errors import RateLimitExceeded
import os
from typing import Optional, List, Dict, Any
from datetime import datetime, timedelta, timezone
import uuid
import re
import hashlib
import asyncio
import threading
import time
import tempfile
from pathlib import Path

# Add current directory to Python path for Vercel deployment
import sys
current_dir = os.path.dirname(os.path.abspath(__file__))
if current_dir not in sys.path:
    sys.path.insert(0, current_dir)

# Import our lightweight PDF RAG functionality
from rag_lightweight import DocumentProcessor, get_or_create_rag_system
# Import ChatOpenAI for document summarization
from aimakerspace.openai_utils.chatmodel import ChatOpenAI

# Initialize FastAPI application with comprehensive OpenAPI configuration
app = FastAPI(
    title="OpenAI Chat API (Lightweight)",
    description="""
    A lightweight FastAPI-based backend service optimized for Vercel deployment:
    
    * **Streaming Chat Interface**: Real-time chat with OpenAI's GPT models
    * **Session Management**: Secure session-based authentication
    * **Conversation History**: Persistent conversation storage and retrieval
    * **Multi-format Document RAG**: Upload and query documents (PDF, Word, PowerPoint) using simple text extraction
    * **Rate Limiting**: Built-in protection against abuse
    * **Security**: Input validation and secure API key handling
    
    ## Features
    
    - 🔄 **Real-time Streaming**: Get responses as they're generated
    - 💬 **Conversation Management**: Create, retrieve, and delete conversations
    - 📄 **Document Processing**: Upload and query documents (PDF, Word, PowerPoint) with lightweight extraction
    - 🔍 **RAG Queries**: Ask questions about uploaded documents
    - 🛡️ **Security**: Rate limiting, input validation, and secure session management
    - 📚 **Interactive Docs**: Test the API directly from the browser
    
    ## Optimization Notes
    
    This version uses lightweight dependencies (PyPDF2, pdfplumber) instead of heavy ML libraries
    to work within Vercel's free tier memory constraints.
    
    ## Authentication
    
    This API uses session-based authentication. First, create a session with your OpenAI API key, then use the returned session ID in subsequent requests.
    """,
    version="1.0.0-lightweight",
    contact={
        "name": "API Support",
        "email": "support@example.com",
    },
    license_info={
        "name": "MIT",
        "url": "https://opensource.org/licenses/MIT",
    },
    servers=[
        {
            "url": "http://localhost:8000",
            "description": "Development server"
        },
        {
            "url": "https://your-production-domain.com",
            "description": "Production server"
        }
    ],
    openapi_tags=[
        {
            "name": "Authentication",
            "description": "Session management and authentication endpoints"
        },
        {
            "name": "Chat",
            "description": "Chat and conversation management endpoints"
        },
        {
            "name": "PDF RAG",
            "description": "PDF upload and RAG query endpoints"
        },
        {
            "name": "Health",
            "description": "Health check and system status endpoints"
        }
    ]
)

# Initialize rate limiter
limiter = Limiter(key_func=get_remote_address)
app.state.limiter = limiter
app.add_exception_handler(RateLimitExceeded, _rate_limit_exceeded_handler)

# Configure CORS (Cross-Origin Resource Sharing) middleware
# This allows the API to be accessed from different domains/origins
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Allows requests from any origin
    allow_credentials=True,  # Allows cookies to be included in requests
    allow_methods=["*"],  # Allows all HTTP methods (GET, POST, etc.)
    allow_headers=["*"],  # Allows all headers in requests
)

# In-memory storage for conversations (in production, use a proper database)
# Structure: {session_id: {conversation_id: conversation_data}}
conversations: Dict[str, Dict[str, Dict[str, Any]]] = {}

# Session management
# Structure: {session_id: {"api_key": hashed_api_key, "last_access": datetime}}
sessions: Dict[str, Dict[str, Any]] = {}

def hash_api_key(api_key: str) -> str:
    """Hash the API key using SHA-256 for secure storage key generation"""
    return hashlib.sha256(api_key.encode('utf-8')).hexdigest()

def create_session(api_key: str) -> str:
    """Create a new session for the given API key"""
    session_id = str(uuid.uuid4())    
    sessions[session_id] = {
        "last_access": datetime.now(timezone.utc)
    }
    
    return session_id

def get_session(session_id: str) -> Optional[str]:
    """Get the hashed API key for a session, return None if session doesn't exist"""
    if session_id not in sessions:
        return None
    
    # Update session access time
    sessions[session_id]["last_access"] = datetime.now(timezone.utc)
    return sessions[session_id]

def get_session_conversations(session_id: str) -> Dict[str, Dict[str, Any]]:
    """Get conversations scoped to a specific session."""
    if session_id not in conversations:
        conversations[session_id] = {}
    return conversations[session_id]

def cleanup_inactive_conversations():
    """Clean up conversations and sessions that haven't been used in the last 10 minutes"""
    current_time = datetime.now(timezone.utc)
    inactive_sessions = []
    # Identify inactive sessions
    for session_id, session_data in sessions.items():
        if current_time - session_data["last_access"] > timedelta(minutes=10):
            inactive_sessions.append(session_id)
    # Remove conversations and sessions for inactive session_ids
    for session_id in inactive_sessions:
        if session_id in conversations:
            del conversations[session_id]
        del sessions[session_id]
        print(f"Cleaned up inactive session and its conversations: {session_id[:8]}...")

def start_cleanup_scheduler():
    """Start the background cleanup scheduler"""
    def cleanup_loop():
        while True:
            try:
                cleanup_inactive_conversations()
                time.sleep(60)  # Run cleanup every minute
            except Exception as e:
                print(f"Error in cleanup scheduler: {e}")
                time.sleep(60)
    
    cleanup_thread = threading.Thread(target=cleanup_loop, daemon=True)
    cleanup_thread.start()
    print("Started conversation cleanup scheduler")

# Start the cleanup scheduler when the module loads
start_cleanup_scheduler()

# Define the data model for chat requests using Pydantic
# This ensures incoming request data is properly validated
class ChatRequest(BaseModel):
    conversation_id: Optional[str] = None  # ID to continue existing conversation
    developer_message: str  # Message from the developer/system
    user_message: str      # Message from the user
    model: Optional[str] = "gpt-4.1-mini"  # Optional model selection with default
    api_key: str          # API key for authentication
    provider: Optional[str] = "openai"  # Provider selection: "openai" or "together"
    
    @field_validator('api_key')
    @classmethod
    def validate_api_key(cls, v):
        """Validate API key format"""
        if not v or not isinstance(v, str):
            raise ValueError('API key is required')
        
        # Just check that it's not empty and is a string
        if len(v.strip()) == 0:
            raise ValueError('API key cannot be empty')
        
        return v
    
    @field_validator('provider')
    @classmethod
    def validate_provider(cls, v):
        """Validate provider selection"""
        if not v:
            return "openai"  # Default provider
        
        allowed_providers = ["openai", "together"]
        if v.lower() not in allowed_providers:
            raise ValueError(f'Invalid provider: {v}. Allowed providers: {", ".join(allowed_providers)}')
        
        return v.lower()
    
    @field_validator('user_message')
    @classmethod
    def validate_user_message(cls, v):
        """Validate user message content"""
        if not v or not isinstance(v, str):
            raise ValueError('User message is required')
        
        if len(v.strip()) == 0:
            raise ValueError('User message cannot be empty')
        
        if len(v) > 10000:  # Reasonable limit for message length
            raise ValueError('User message is too long (max 10,000 characters)')
        
        return v.strip()
    
    @field_validator('developer_message')
    @classmethod
    def validate_developer_message(cls, v):
        """Validate developer/system message content"""
        if not v or not isinstance(v, str):
            raise ValueError('Developer message is required')
        
        if len(v) > 5000:  # Reasonable limit for system message
            raise ValueError('Developer message is too long (max 5,000 characters)')
        
        return v.strip()
    
    @field_validator('model')
    @classmethod
    def validate_model(cls, v):
        """Validate model selection"""
        if not v:
            return "gpt-4.1-mini"  # Default model
        
        # List of allowed models for OpenAI
        openai_models = [
            "gpt-4", "gpt-4-mini", "gpt-4-turbo", "gpt-4o", "gpt-4o-mini",
            "gpt-4.1", "gpt-4.1-mini", "gpt-4.1-nano", "gpt-5", "gpt-5-mini", "gpt-5-nano"
        ]
        
        # List of allowed models for Together.ai
        together_models = [
            "deepseek-ai/DeepSeek-R1", "deepseek-ai/DeepSeek-V3.1", "deepseek-ai/DeepSeek-V3",
            "meta-llama/Llama-3.3-70B-Instruct-Turbo", 
            "openai/gpt-oss-20b", "openai/gpt-oss-120b"
        ]
        
        all_models = openai_models + together_models
        
        if v not in all_models:
            raise ValueError(f'Invalid model: {v}. Allowed models: {", ".join(all_models)}')
        
        return v
    
    @field_validator('conversation_id')
    @classmethod
    def validate_conversation_id(cls, v):
        """Validate conversation ID format"""
        if v is None:
            return v
        
        if not isinstance(v, str):
            raise ValueError('Conversation ID must be a string')
        
        if len(v) > 100:
            raise ValueError('Conversation ID is too long')
        
        # Allow alphanumeric, hyphens, and underscores
        if not re.match(r'^[A-Za-z0-9_-]+$', v):
            raise ValueError('Conversation ID contains invalid characters')
        
        return v

class Message(BaseModel):
    role: str  # "system", "user", or "assistant"
    content: str
    timestamp: datetime

class ConversationResponse(BaseModel):
    conversation_id: str
    message: str
    timestamp: datetime

class SessionRequest(BaseModel):
    api_key: str
    provider: Optional[str] = "openai"  # Provider selection: "openai" or "together"
    
    @field_validator('api_key')
    @classmethod
    def validate_api_key(cls, v):
        """Validate API key format"""
        if not v or not isinstance(v, str):
            raise ValueError('API key is required')
        
        if len(v.strip()) == 0:
            raise ValueError('API key cannot be empty')
        
        return v
    
    @field_validator('provider')
    @classmethod
    def validate_provider(cls, v):
        """Validate provider selection"""
        if not v:
            return "openai"  # Default provider
        
        allowed_providers = ["openai", "together"]
        if v.lower() not in allowed_providers:
            raise ValueError(f'Invalid provider: {v}. Allowed providers: {", ".join(allowed_providers)}')
        
        return v.lower()

class SessionResponse(BaseModel):
    session_id: str
    message: str

class DocumentUploadResponse(BaseModel):
    document_id: str
    message: str
    chunk_count: int
    file_name: str
    file_type: str
    summary: Optional[str] = None
    suggested_questions: Optional[List[str]] = None

class RAGQueryRequest(BaseModel):
    question: str
    developer_message: str  # System message from the developer/UI
    k: Optional[int] = 5  # Number of relevant chunks to retrieve
    model: Optional[str] = "gpt-4.1"  # Model selection for RAG queries
    mode: Optional[str] = "rag"  # RAG mode: "rag" or "topic-explorer"
    provider: Optional[str] = "openai"  # Provider selection: "openai" or "together"
    
    @field_validator('question')
    @classmethod
    def validate_question(cls, v):
        """Validate question content"""
        if not v or not isinstance(v, str):
            raise ValueError('Question is required')
        
        if len(v.strip()) == 0:
            raise ValueError('Question cannot be empty')
        
        if len(v) > 2000:  # Reasonable limit for question length
            raise ValueError('Question is too long (max 2,000 characters)')
        
        return v.strip()
    
    @field_validator('developer_message')
    @classmethod
    def validate_developer_message(cls, v):
        """Validate developer/system message content"""
        if not v or not isinstance(v, str):
            raise ValueError('Developer message is required')
        
        if len(v) > 5000:  # Reasonable limit for system message
            raise ValueError('Developer message is too long (max 5,000 characters)')
        
        return v.strip()
    
    @field_validator('k')
    @classmethod
    def validate_k(cls, v):
        """Validate k parameter"""
        if v is None:
            return 5
        
        if not isinstance(v, int):
            raise ValueError('k must be an integer')
        
        if v < 1 or v > 20:
            raise ValueError('k must be between 1 and 20')
        
        return v
    
    @field_validator('model')
    @classmethod
    def validate_model(cls, v):
        """Validate model selection"""
        if not v:
            return "gpt-4.1-mini"  # Default model
        
        # List of allowed models for OpenAI
        openai_models = [
            "gpt-4", "gpt-4-mini", "gpt-4-turbo", "gpt-4o", "gpt-4o-mini",
            "gpt-4.1", "gpt-4.1-mini", "gpt-4.1-nano", "gpt-5", "gpt-5-mini", "gpt-5-nano"
        ]
        
        # List of allowed models for Together.ai
        together_models = [
            "deepseek-ai/DeepSeek-R1", "deepseek-ai/DeepSeek-V3.1", "deepseek-ai/DeepSeek-V3",
            "meta-llama/Llama-3.3-70B-Instruct-Turbo",
            "openai/gpt-oss-20b", "openai/gpt-oss-120b"
        ]
        
        all_models = openai_models + together_models
        
        if v not in all_models:
            raise ValueError(f'Invalid model: {v}. Allowed models: {", ".join(all_models)}')
        
        return v
    
    @field_validator('provider')
    @classmethod
    def validate_provider(cls, v):
        """Validate provider selection"""
        if not v:
            return "openai"  # Default provider
        
        allowed_providers = ["openai", "together"]
        if v.lower() not in allowed_providers:
            raise ValueError(f'Invalid provider: {v}. Allowed providers: {", ".join(allowed_providers)}')
        
        return v.lower()

class RAGQueryResponse(BaseModel):
    answer: str
    relevant_chunks_count: int
    document_info: Dict[str, Any]

# Endpoint to create a new session
@app.post(
    "/api/session",
    response_model=SessionResponse,
    tags=["Authentication"],
    summary="Create a new session",
    description="Create a new authenticated session using your OpenAI API key. Returns a session ID that you'll use for subsequent requests.",
    responses={
        200: {"description": "Session created successfully"},
        500: {"description": "Internal server error"}
    }
)
@limiter.limit("5/minute")  # Limit to 5 session creations per minute per IP
async def create_session_endpoint(request: Request, session_request: SessionRequest):
    try:
        session_id = create_session(session_request.api_key)
        return SessionResponse(
            session_id=session_id,
            message="Session created successfully"
        )
    except Exception as e:
        print(f"Error creating session: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

# Define the main chat endpoint that handles POST requests
@app.post(
    "/api/chat",
    tags=["Chat"],
    summary="Send a chat message",
    description="Send a message to the AI and receive a streaming response. Supports conversation history and model selection.",
    responses={
        200: {"description": "Streaming chat response"},
        401: {"description": "Invalid or expired session"},
        429: {"description": "Rate limit exceeded"},
        500: {"description": "Internal server error"}
    }
)
@limiter.limit("10/minute")  # Limit to 10 requests per minute per IP
async def chat(
    request: Request, 
    chat_request: ChatRequest,
    x_session_id: str = Header(..., alias="X-Session-ID", description="Session ID for authentication")
):
    try:
        # Use session ID from header parameter
        session_id = x_session_id
        
        # Validate session
        if not get_session(session_id):
            raise HTTPException(status_code=401, detail="Invalid or expired session")
        
        # Debug logging
        print(f"Received chat request: session_id={session_id[:8]}..., provider={chat_request.provider}, model={chat_request.model}, user_message_length={len(chat_request.user_message)}")
        
        # Initialize OpenAI client with the provided API key and provider
        client_kwargs = {"api_key": chat_request.api_key}
        if chat_request.provider == "together":
            client_kwargs["base_url"] = "https://api.together.xyz/v1"
        client = OpenAI(**client_kwargs)
        
        # Get session-specific conversations
        user_conversations = get_session_conversations(session_id)
        
        # Generate or retrieve conversation ID
        conversation_id = chat_request.conversation_id or str(uuid.uuid4())
        
        # Initialize conversation if it doesn't exist
        if conversation_id not in user_conversations:
            user_conversations[conversation_id] = {
                "messages": [],
                "system_message": chat_request.developer_message,
                "title": None,  # Will be set when first user message is added
                "created_at": datetime.now(timezone.utc),
                "last_updated": datetime.now(timezone.utc),
                "mode": "regular"  # Default to regular chat mode
            }
        
        # Add user message to conversation history
        user_message = Message(
            role="user",
            content=chat_request.user_message,
            timestamp=datetime.now(timezone.utc)
        )
        user_conversations[conversation_id]["messages"].append(user_message)
        user_conversations[conversation_id]["last_updated"] = datetime.now(timezone.utc)
        
        # Set conversation title from first user message if not already set
        if user_conversations[conversation_id]["title"] is None:
            # Use first line of the user message as title (max 50 characters)
            first_line = chat_request.user_message.split('\n')[0].strip()
            user_conversations[conversation_id]["title"] = first_line[:50] + ("..." if len(first_line) > 50 else "")
        
        # Build the full conversation context for OpenAI
        messages_for_openai = [
            {"role": "system", "content": user_conversations[conversation_id]["system_message"]}
        ]
        
        # Add conversation history (limit to last 20 messages to avoid token limits)
        recent_messages = user_conversations[conversation_id]["messages"][-20:]
        for msg in recent_messages:
            # Map our roles to OpenAI's expected roles
            # By using alternating user and assistant messages, 
            # you capture the previous state of a conversation in one request to the model.
            openai_role = "assistant" if msg.role == "assistant" else msg.role
            messages_for_openai.append({
                "role": openai_role,
                "content": msg.content
            })
        
        # Create an async generator function for streaming responses
        async def generate():
            try:
                # Create a streaming chat completion request
                stream = client.chat.completions.create(
                    model=chat_request.model,
                    messages=messages_for_openai,
                    stream=True  # Enable streaming response
                )
                
                # Collect the full response for storage
                full_response = ""
                
                # Yield each chunk of the response as it becomes available
                for chunk in stream:
                    # Some providers may send chunks without choices or content (e.g., role updates or keep-alives)
                    try:
                        choices = getattr(chunk, "choices", None)
                        if not choices or len(choices) == 0:
                            continue
                        choice0 = choices[0]
                        delta = getattr(choice0, "delta", None)
                        content = getattr(delta, "content", None) if delta is not None else None
                        if content:
                            full_response += content
                            yield content
                    except Exception:
                        # Be tolerant to provider-specific streaming variations
                        continue
                
                # Store the assistant's response in conversation history
                assistant_message = Message(
                    role="assistant",
                    content=full_response,
                    timestamp=datetime.now(timezone.utc)
                )
                user_conversations[conversation_id]["messages"].append(assistant_message)
                user_conversations[conversation_id]["last_updated"] = datetime.now(timezone.utc)
                
            except Exception as e:
                # Remove the user message if the API call failed
                if user_conversations[conversation_id]["messages"]:
                    user_conversations[conversation_id]["messages"].pop()
                raise e

        # Return a streaming response to the client with conversation ID in headers
        response = StreamingResponse(generate(), media_type="text/plain")
        response.headers["X-Conversation-ID"] = conversation_id
        return response
    
    except Exception as e:
        # Handle any errors that occur during processing
        print(f"Error in chat endpoint: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

# Endpoint to get conversation history
@app.get(
    "/api/conversations/{conversation_id}",
    tags=["Chat"],
    summary="Get conversation history",
    description="Retrieve the complete history of a specific conversation including all messages and metadata.",
    responses={
        200: {"description": "Conversation history retrieved successfully"},
        401: {"description": "Invalid or expired session"},
        404: {"description": "Conversation not found"},
        429: {"description": "Rate limit exceeded"}
    }
)
@limiter.limit("30/minute")  # Limit to 30 requests per minute per IP
async def get_conversation(
    request: Request, 
    conversation_id: str,
    x_session_id: str = Header(..., alias="X-Session-ID", description="Session ID for authentication")
):
    # Use session ID from header parameter
    session_id = x_session_id
    
    # Validate session
    if not get_session(session_id):
        raise HTTPException(status_code=401, detail="Invalid or expired session")
    
    # Get session-specific conversations
    user_conversations = get_session_conversations(session_id)
    
    if conversation_id not in user_conversations:
        raise HTTPException(status_code=404, detail="Conversation not found")
    
    return {
        "conversation_id": conversation_id,
        "title": user_conversations[conversation_id].get("title", "New Conversation"),
        "system_message": user_conversations[conversation_id]["system_message"],
        "messages": user_conversations[conversation_id]["messages"],
        "created_at": user_conversations[conversation_id]["created_at"],
        "last_updated": user_conversations[conversation_id]["last_updated"],
        "mode": user_conversations[conversation_id].get("mode", "regular")
    }

# Endpoint to list all conversations
@app.get(
    "/api/conversations",
    tags=["Chat"],
    summary="List all conversations",
    description="Get a list of all conversations for the authenticated user, sorted by last updated time.",
    responses={
        200: {"description": "List of conversations retrieved successfully"},
        401: {"description": "Invalid or expired session"},
        429: {"description": "Rate limit exceeded"}
    }
)
@limiter.limit("20/minute")  # Limit to 20 requests per minute per IP
async def list_conversations(
    request: Request,
    x_session_id: str = Header(..., alias="X-Session-ID", description="Session ID for authentication")
):
    # Use session ID from header parameter
    session_id = x_session_id
    
    # Validate session
    if not get_session(session_id):
        raise HTTPException(status_code=401, detail="Invalid or expired session")
    
    # Get session-specific conversations
    user_conversations = get_session_conversations(session_id)
    
    conversation_list = []
    for conv_id, conv_data in user_conversations.items():
        conversation_list.append({
            "conversation_id": conv_id,
            "title": conv_data.get("title", "New Conversation"),
            "system_message": conv_data["system_message"],
            "message_count": len(conv_data["messages"]),
            "created_at": conv_data["created_at"],
            "last_updated": conv_data["last_updated"],
            "mode": conv_data.get("mode", "regular")
        })
    
    # Sort by last updated (most recent first)
    conversation_list.sort(key=lambda x: x["last_updated"], reverse=True)
    return conversation_list

# Endpoint to delete a conversation
@app.delete(
    "/api/conversations/{conversation_id}",
    tags=["Chat"],
    summary="Delete a conversation",
    description="Permanently delete a specific conversation and all its messages.",
    responses={
        200: {"description": "Conversation deleted successfully"},
        401: {"description": "Invalid or expired session"},
        404: {"description": "Conversation not found"},
        429: {"description": "Rate limit exceeded"}
    }
)
@limiter.limit("10/minute")  # Limit to 10 requests per minute per IP
async def delete_conversation(
    request: Request, 
    conversation_id: str,
    x_session_id: str = Header(..., alias="X-Session-ID", description="Session ID for authentication")
):
    # Use session ID from header parameter
    session_id = x_session_id
    
    # Validate session
    if not get_session(session_id):
        raise HTTPException(status_code=401, detail="Invalid or expired session")
    
    # Get session-specific conversations
    user_conversations = get_session_conversations(session_id)
    
    if conversation_id not in user_conversations:
        raise HTTPException(status_code=404, detail="Conversation not found")
    
    del user_conversations[conversation_id]
    return {"message": "Conversation deleted successfully"}

# Endpoint to clear all conversations for a specific user
@app.delete(
    "/api/conversations",
    tags=["Chat"],
    summary="Clear all conversations",
    description="Permanently delete all conversations for the authenticated user. This action cannot be undone.",
    responses={
        200: {"description": "All conversations cleared successfully"},
        401: {"description": "Invalid or expired session"},
        429: {"description": "Rate limit exceeded"}
    }
)
@limiter.limit("5/minute")  # Limit to 5 requests per minute per IP (more restrictive)
async def clear_all_conversations(
    request: Request,
    x_session_id: str = Header(..., alias="X-Session-ID", description="Session ID for authentication")
):
    # Use session ID from header parameter
    session_id = x_session_id
    
    # Validate session
    if not get_session(session_id):
        raise HTTPException(status_code=401, detail="Invalid or expired session")
    
    # Get session-specific conversations and clear them
    user_conversations = get_session_conversations(session_id)
    user_conversations.clear()
    
    return {"message": "All conversations cleared successfully"}

# Document Upload endpoint
@app.post(
    "/api/upload-document",
    response_model=DocumentUploadResponse,
    tags=["Document RAG"],
    summary="Upload a document",
    description="Upload and process a document (PDF, Word, PowerPoint) for RAG (Retrieval-Augmented Generation) functionality. The document will be chunked and indexed for later querying.",
    responses={
        200: {"description": "Document processed and indexed successfully"},
        400: {"description": "Invalid file type or size"},
        401: {"description": "Invalid or expired session"},
        429: {"description": "Rate limit exceeded"},
        500: {"description": "Internal server error"}
    }
)
@limiter.limit("3/minute")  # Limit to 3 document uploads per minute per IP
async def upload_document(
    request: Request,
    file: UploadFile = File(..., description="Document file to upload (PDF, DOCX, PPTX - max 20MB)"),
    x_session_id: str = Header(..., alias="X-Session-ID", description="Session ID for authentication"),
    x_api_key: str = Header(..., alias="X-API-Key", description="API key for document processing"),
    x_provider: str = Header("openai", alias="X-Provider", description="Provider for document processing (openai or together)")
):
    """Upload and process a document file for RAG functionality."""
    try:
        # Use session ID, API key, and provider from header parameters
        session_id = x_session_id
        api_key = x_api_key
        provider = x_provider.lower()
        
        # Validate provider
        if provider not in ["openai", "together"]:
            raise HTTPException(status_code=400, detail="Invalid provider. Must be 'openai' or 'together'")
        
        # Get hashed API key from session
        if not get_session(session_id):
            raise HTTPException(status_code=401, detail="Invalid or expired session")
        
        # Validate file type
        if not file.filename:
            raise HTTPException(status_code=400, detail="No file provided")
        
        file_extension = file.filename.lower().split('.')[-1]
        supported_types = ['pdf', 'docx', 'doc', 'pptx', 'ppt']
        
        if file_extension not in supported_types:
            supported_types_str = ', '.join(f'.{t}' for t in supported_types)
            raise HTTPException(
                status_code=400, 
                detail=f"Unsupported file type: .{file_extension}. Supported types: {supported_types_str}"
            )
        
        # Validate file size (max20)
        file_content = await file.read()
        if len(file_content) > 20 * 1024 * 1024:  # 20MB
            raise HTTPException(status_code=400, detail="File size too large (max 20MB)")
        
        # Create temporary file with appropriate extension
        temp_suffix = f'.{file_extension}'
        with tempfile.NamedTemporaryFile(delete=False, suffix=temp_suffix) as temp_file:
            temp_file.write(file_content)
            temp_file_path = temp_file.name
        
        try:
            # Process document using DocumentProcessor
            document_processor = DocumentProcessor()
            processed_data = document_processor.process_document(temp_file_path)
            
            # Generate document ID
            # document_id = str(uuid.uuid4())
            document_id = file.filename
            
            # Get or create RAG system for this session with the specified provider
            rag_system = get_or_create_rag_system(session_id, api_key, provider)
            
            # Index the document
            await rag_system.index_document(
                document_id=document_id,
                chunks=processed_data["chunks"],
                metadata=processed_data["metadata"]
            )
            
            # Generate document summary and suggested questions using ChatOpenAI
            summary = None
            suggested_questions = None
            
            try:
                # Initialize ChatOpenAI with the provided API key and provider
                chat_model = ChatOpenAI(api_key=api_key, provider=provider)
                
                # Prepare document content for summarization
                document_content = "\n\n".join(processed_data["chunks"])
                
                # System message for summarization
                system_message = """You are a helpful assistant. Please, summarize this document content and return 5 suggested prompts/questions about it. These questions will be presented to the user so it can start a conversation with you about.

Please respond with a JSON object in the following format:
{
  "summary": "Brief summary of the document content",
  "suggested_questions": ["Question 1", "Question 2", "Question 3", "Question 4", "Question 5"]
}"""
                
                # Create the prompt for summarization
                user_message = f"Please summarize the following document content and provide 5 suggested questions:\n\n{document_content}"
                
                # Generate summary and suggested questions
                response = chat_model.run(
                    messages=[
                        {"role": "system", "content": system_message},
                        {"role": "user", "content": user_message}
                    ],
                    model="gpt-4.1-mini" if provider == "openai" else "deepseek-ai/DeepSeek-V3.1"
                )
                
                # Parse the JSON response to extract summary and questions
                try:
                    import json
                    parsed_response = json.loads(response)
                    summary = parsed_response.get("summary", "Summary not available")
                    suggested_questions = parsed_response.get("suggested_questions", [])
                    
                    # Ensure we have exactly 5 questions
                    if len(suggested_questions) < 5:
                        # Add generic questions if we don't have enough
                        generic_questions = [
                            "What are the main topics covered in this document?",
                            "Can you explain the key concepts mentioned?",
                            "What are the important details I should know?",
                            "How does this content relate to practical applications?",
                            "What questions do you have about this material?"
                        ]
                        while len(suggested_questions) < 5:
                            suggested_questions.append(generic_questions[len(suggested_questions)])
                    elif len(suggested_questions) > 5:
                        # Trim to 5 questions if we have too many
                        suggested_questions = suggested_questions[:5]
                        
                except json.JSONDecodeError:
                    # If JSON parsing fails, use the raw response as summary
                    summary = response
                    suggested_questions = [
                        "What are the main topics covered in this document?",
                        "Can you explain the key concepts mentioned?",
                        "What are the important details I should know?",
                        "How does this content relate to practical applications?",
                        "What questions do you have about this material?"
                    ]
                
            except Exception as e:
                print(f"Error generating document summary: {str(e)}")
                # Continue without summary if generation fails
                summary = "Summary generation failed due to an error."
                suggested_questions = [
                    "What are the main topics covered in this document?",
                    "Can you explain the key concepts mentioned?",
                    "What are the important details I should know?",
                    "How does this content relate to practical applications?",
                    "What questions do you have about this material?"
                ]
            
            return DocumentUploadResponse(
                document_id=document_id,
                message=f"{processed_data['metadata']['file_type'].upper()} document processed and indexed successfully",
                chunk_count=processed_data["chunk_count"],
                file_name=document_id, #processed_data["metadata"]["file_name"],
                file_type=processed_data["metadata"]["file_type"],
                summary=summary,
                suggested_questions=suggested_questions
            )
            
        finally:
            # Clean up temporary file
            os.unlink(temp_file_path)
    
    except Exception as e:
        print(f"Error in document upload: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

# RAG Query endpoint
@app.post(
    "/api/rag-query",
    response_model=RAGQueryResponse,
    tags=["Document RAG"],
    summary="Query uploaded documents",
    description="Ask questions about uploaded documents (PDF, Word, PowerPoint) using RAG (Retrieval-Augmented Generation). Returns relevant answers based on document content.",
    responses={
        200: {"description": "RAG query processed successfully"},
        401: {"description": "Invalid or expired session"},
        429: {"description": "Rate limit exceeded"},
        500: {"description": "Internal server error"}
    }
)
@limiter.limit("20/minute")  # Limit to 20 RAG queries per minute per IP
async def rag_query(
    request: Request, 
    query_request: RAGQueryRequest,
    x_session_id: str = Header(..., alias="X-Session-ID", description="Session ID for authentication"),
    x_api_key: str = Header(..., alias="X-API-Key", description="OpenAI API key for RAG processing"),
    x_conversation_id: Optional[str] = Header(None, alias="X-Conversation-ID", description="Conversation ID for tracking RAG queries")
):
    """Query the RAG system with a question."""
    try:
        # Use session ID and API key from header parameters
        session_id = x_session_id
        api_key = x_api_key

        # Debug logging
        print(f"Received RAG query request: session_id={session_id[:8]}..., provider={query_request.provider}, model={query_request.model}, question_length={len(query_request.question)}")

        # Validate session
        if not get_session(session_id):
            raise HTTPException(status_code=401, detail="Invalid or expired session")
        
        # Get RAG system for this session with the specified model and provider
        rag_system = get_or_create_rag_system(session_id, api_key, query_request.provider)
        
        # Query the RAG system with the specified mode and developer message
        answer = rag_system.query(query_request.question, k=query_request.k, mode=query_request.mode, model_name=query_request.model, system_message=query_request.developer_message)
        
        # Get document info
        doc_info = rag_system.get_document_info()
        
        # Get relevant chunks count (approximate)
        relevant_chunks = rag_system.search_relevant_chunks(query_request.question, k=query_request.k)
        relevant_chunks_count = len(relevant_chunks)
        
        # Store the RAG conversation in session-scoped conversation history
        user_conversations = get_session_conversations(session_id)
        
        # Generate or retrieve conversation ID from header parameter
        conversation_id = x_conversation_id or str(uuid.uuid4())
        
        # Initialize conversation if it doesn't exist
        if conversation_id not in user_conversations:
            user_conversations[conversation_id] = {
                "messages": [],
                "system_message": query_request.developer_message,
                "title": None,  # Will be set when first user message is added
                "created_at": datetime.now(timezone.utc),
                "last_updated": datetime.now(timezone.utc),
                "mode": query_request.mode or "rag"  # RAG mode for document queries
            }
        
        # Add user message to conversation history
        user_message = Message(
            role="user",
            content=query_request.question,
            timestamp=datetime.now(timezone.utc)
        )
        user_conversations[conversation_id]["messages"].append(user_message)
        user_conversations[conversation_id]["last_updated"] = datetime.now(timezone.utc)
        
        # Set conversation title from first user message if not already set
        if user_conversations[conversation_id]["title"] is None:
            # Use first line of the user message as title (max 50 characters)
            first_line = query_request.question.split('\n')[0].strip()
            user_conversations[conversation_id]["title"] = first_line[:50] + ("..." if len(first_line) > 50 else "")
        
        # Add assistant message to conversation history
        assistant_message = Message(
            role="assistant",
            content=answer,
            timestamp=datetime.now(timezone.utc)
        )
        user_conversations[conversation_id]["messages"].append(assistant_message)
        user_conversations[conversation_id]["last_updated"] = datetime.now(timezone.utc)
        
        # Create response with conversation ID in headers
        response = RAGQueryResponse(
            answer=answer,
            relevant_chunks_count=relevant_chunks_count,
            document_info=doc_info
        )
        
        # Return response with conversation ID in headers
        from fastapi.responses import JSONResponse
        return JSONResponse(
            content=response.model_dump(),
            headers={"X-Conversation-ID": conversation_id}
        )
    
    except Exception as e:
        print(f"Error in RAG query: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

# Get document info endpoint
@app.get(
    "/api/documents",
    tags=["Document RAG"],
    summary="Get uploaded documents info",
    description="Retrieve information about all uploaded documents for the current session, including metadata and chunk counts.",
    responses={
        200: {"description": "Document information retrieved successfully"},
        401: {"description": "Invalid or expired session"},
        429: {"description": "Rate limit exceeded"},
        500: {"description": "Internal server error"}
    }
)
@limiter.limit("10/minute")  # Limit to 10 requests per minute per IP
async def get_documents(
    request: Request,
    x_session_id: str = Header(..., alias="X-Session-ID", description="Session ID for authentication"),
    x_api_key: str = Header(..., alias="X-API-Key", description="API key for document processing"),
    x_provider: str = Header("openai", alias="X-Provider", description="Provider for document processing (openai or together)")
):
    """Get information about uploaded documents for the session."""
    try:
        # Use session ID, API key, and provider from header parameters
        session_id = x_session_id
        api_key = x_api_key
        provider = x_provider.lower()
        
        # Validate provider
        if provider not in ["openai", "together"]:
            raise HTTPException(status_code=400, detail="Invalid provider. Must be 'openai' or 'together'")
        
        # Validate session
        if not get_session(session_id):
            raise HTTPException(status_code=401, detail="Invalid or expired session")
        
        # Get RAG system for this session with the specified provider
        rag_system = get_or_create_rag_system(session_id, api_key, provider)
        
        # Get document info
        doc_info = rag_system.get_document_info()
        
        return doc_info
    
    except Exception as e:
        print(f"Error getting documents: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

# Define a health check endpoint to verify API status
@app.get(
    "/api/health",
    tags=["Health"],
    summary="Health check",
    description="Check the API health status. Returns OK if the service is running properly.",
    responses={
        200: {"description": "API is healthy and running"}
    }
)
async def health_check():
    return {"status": "ok"}

# Entry point for running the application directly
if __name__ == "__main__":
    import uvicorn
    # Start the server on all network interfaces (0.0.0.0) on port 8000
    uvicorn.run(app, host="0.0.0.0", port=8000)
